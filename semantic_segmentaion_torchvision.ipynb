{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2721868",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d8a1df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "import torchmetrics\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import albumentations as A\n",
    "import seaborn as sns\n",
    "from train_model import train_model\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torchvision.ops import focal_loss\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a521f8f",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75a383c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 20+1 #including background-class\n",
    "MODEL_PATH = 'model/output/model.pth'\n",
    "NUM_EPOCHS = 1000\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15cd61b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = 'data/processed/images/'\n",
    "mask_folder = 'data/processed/masks/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75babe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = TacoDataset(image_folder, mask_folder, transform=train_transform)\n",
    "# labels_count = torch.zeros(NUM_CLASSES).to(device)\n",
    "\n",
    "# for i, (_, masks) in enumerate(dataset):\n",
    "#         print(i, end=\"\\r\")\n",
    "#         labels = torch.flatten(masks)\n",
    "#         labels_count += torch.bincount(labels, minlength=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5668cc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_inverse_frequencies = 1.0 / labels_count\n",
    "# class_weights = class_inverse_frequencies / torch.sum(class_inverse_frequencies)\n",
    "# class_weights[0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29eebb14",
   "metadata": {},
   "source": [
    "# Trainning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4d0f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has been loaded!\n",
      "Creating dataloaders...\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "model = train_model(MODEL_PATH,\n",
    "           NUM_CLASSES,\n",
    "           BATCH_SIZE,\n",
    "           NUM_EPOCHS,\n",
    "           image_folder, mask_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9ed38c",
   "metadata": {},
   "source": [
    "# Eval model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0cb3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "example_of_preds = []\n",
    "\n",
    "preds_arrays = []\n",
    "mask_arrays = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    epoch_iou = 0\n",
    "    for n, (images, masks) in enumerate(test_dataloader):\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "        \n",
    "        outputs = model(images)['out']\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        epoch_iou += IoU(preds, masks)\n",
    "        \n",
    "        preds_arrays.append(torch.flatten(masks).cpu().numpy())\n",
    "        mask_arrays.append(torch.flatten(preds).cpu().numpy())\n",
    "        \n",
    "        if n >= len(test_dataloader) - 5:\n",
    "            images = torch.squeeze(images, dim=0).cpu().numpy().transpose(1, 2, 0)\n",
    "            preds_image = preds.cpu().numpy().transpose(1, 2, 0)\n",
    "            mask_image = torch.squeeze(masks, dim=0).cpu().numpy()\n",
    "            example_of_preds.append([images, preds_image, mask_image])\n",
    "\n",
    "    epoch_iou /= len(test_dataloader)\n",
    "    print(f'IoU: {epoch_iou}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb424b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_arrays = np.array(mask_arrays).flatten()\n",
    "preds_arrays = np.array(preds_arrays).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0049f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(mask_arrays, preds_arrays)\n",
    "cm[0][0] = 0 # ignore 0-class\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=False, cmap=\"Blues\", fmt=\"d\")\n",
    "plt.xlabel(\"Predicted labels\")\n",
    "plt.ylabel(\"True labels\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c68a4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, preds_image, mask_image in example_of_preds:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(10, 5))\n",
    "    axes[0].imshow(images)\n",
    "    axes[0].set_title('Original Image')\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    axes[1].imshow(preds_image)\n",
    "    axes[1].set_title('Pred Mask')\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    axes[2].imshow(mask_image)\n",
    "    axes[2].set_title('GT Mask')\n",
    "    axes[2].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d692c8cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
