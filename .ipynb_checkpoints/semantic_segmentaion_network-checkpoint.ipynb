{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3af9594d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "import albumentations as A\n",
    "import json\n",
    "\n",
    "from dataloaders import TacoLoaders\n",
    "from segmentation_models_pytorch import utils\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import *\n",
    "from pycocotools.coco import COCO\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils import visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a03a8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODER = 'mobilenet_v2'\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "ACTIVATION = 'softmax2d'\n",
    "DEVICE = 'cuda'\n",
    "\n",
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)\n",
    "loss = smp.utils.losses.DiceLoss()\n",
    "metrics = [\n",
    "    smp.utils.metrics.IoU(eps=1., activation = None),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc42530f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_network():\n",
    "    \n",
    "    \n",
    "    def __init__(self, loss, metrics):\n",
    "        self.model = smp.Unet(\n",
    "            encoder_name=ENCODER, \n",
    "            encoder_weights=ENCODER_WEIGHTS, \n",
    "            classes=28, \n",
    "            activation=ACTIVATION,\n",
    "        )\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam([ \n",
    "            dict(params=self.model.parameters(), lr=0.0001),\n",
    "        ])\n",
    "        \n",
    "        self.train_epoch = smp.utils.train.TrainEpoch(\n",
    "            self.model, \n",
    "            loss=loss, \n",
    "            metrics=metrics, \n",
    "            optimizer= self.optimizer,\n",
    "            device=DEVICE,\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "        self.valid_epoch = smp.utils.train.ValidEpoch(\n",
    "            self.model, \n",
    "            loss=loss, \n",
    "            metrics=metrics, \n",
    "            device=DEVICE,\n",
    "            verbose=False,\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def run_training(self, loaders, n_epochs=40, save_name='./best_model.pth'):\n",
    "        max_score = 0\n",
    "        for i in range(0, n_epochs):\n",
    "\n",
    "            train_logs = self.train_epoch.run(loaders.train_loader)\n",
    "            valid_logs = self.valid_epoch.run(loaders.valid_loader)\n",
    "            \n",
    "            if i%1==0: \n",
    "                print(f'==Epoch {i}==')\n",
    "                print('Train/Val IoU:')\n",
    "                print(round(train_logs['iou_score'] , 4))\n",
    "                print(round(valid_logs['iou_score'] , 4))\n",
    "\n",
    "            #if max_score < valid_logs['iou_score']:\n",
    "            max_score = valid_logs['iou_score']\n",
    "            torch.save(self.model, save_name)\n",
    "    \n",
    "    def eval(self, dataloader, model_path='./best_model.pth'):\n",
    "        best_model = torch.load(model_path)\n",
    "        test_epoch = smp.utils.train.ValidEpoch(\n",
    "                         model=best_model,\n",
    "                         loss=loss,\n",
    "                         metrics=metrics,\n",
    "                         device=DEVICE,\n",
    "                         verbose=True\n",
    "                      )\n",
    "\n",
    "        logs = test_epoch.run(dataloader)\n",
    "        return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9d9f99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "1200 150 150\n",
      "Example image and mask:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m taco_loaders \u001b[38;5;241m=\u001b[39m TacoLoaders(augmentation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, preprocessing_fn\u001b[38;5;241m=\u001b[39mpreprocessing_fn)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExample image and mask:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mtaco_loaders\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Документы/trash_segmentation_synth/dataloaders.py:161\u001b[0m, in \u001b[0;36mTacoLoaders.show_example\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow_example\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    160\u001b[0m     n \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_dataset))\n\u001b[0;32m--> 161\u001b[0m     image, mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mn\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    162\u001b[0m     visualize(image\u001b[38;5;241m=\u001b[39mimage\u001b[38;5;241m.\u001b[39mtranspose((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m)),\n\u001b[1;32m    163\u001b[0m               mask\u001b[38;5;241m=\u001b[39mmask\u001b[38;5;241m.\u001b[39mtranspose((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m255\u001b[39m)\n",
      "File \u001b[0;32m~/Документы/trash_segmentation_synth/dataloaders.py:36\u001b[0m, in \u001b[0;36mApplyTransform.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m---> 36\u001b[0m     image, mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m# apply augmentations\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maugmentation:\n",
      "File \u001b[0;32m~/anaconda3/envs/cv-env/lib/python3.9/site-packages/torch/utils/data/dataset.py:295\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx]]\n\u001b[0;32m--> 295\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/Документы/trash_segmentation_synth/dataloaders.py:100\u001b[0m, in \u001b[0;36mTacoDatasetSegmentation.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     97\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((img_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheight\u001b[39m\u001b[38;5;124m'\u001b[39m],img_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ann \u001b[38;5;129;01min\u001b[39;00m anns:\n\u001b[0;32m--> 100\u001b[0m     mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmaximum(mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoco_annotation\u001b[38;5;241m.\u001b[39mannToMask(ann) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetSupercategory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mann\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcategory_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    102\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(mask, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# apply minimal_transforms\u001b[39;00m\n",
      "File \u001b[0;32m~/Документы/trash_segmentation_synth/dataloaders.py:65\u001b[0m, in \u001b[0;36mTacoDatasetSegmentation.getSupercategory\u001b[0;34m(category_id)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetSupercategory\u001b[39m(category_id):\n\u001b[0;32m---> 65\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241m.\u001b[39mcoco_annotation_file_path)\n\u001b[1;32m     66\u001b[0m     cat_json_file \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m category \u001b[38;5;129;01min\u001b[39;00m cat_json_file[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategories\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "network = My_network(loss, metrics)\n",
    "taco_loaders = TacoLoaders(augmentation=None, preprocessing_fn=preprocessing_fn)\n",
    "print(\"Example image and mask:\")\n",
    "taco_loaders.show_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f928d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training model:\")\n",
    "network.run_training(taco_loaders, n_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8f1e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Eval model:\")\n",
    "best_model = network.eval(taco_loaders.test_loader)\n",
    "compare_predictions(taco_loaders, best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ed339c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
